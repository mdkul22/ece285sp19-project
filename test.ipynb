{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as td\n",
    "import torch.nn.functional as F\n",
    "import torchvision as tv\n",
    "from PIL import Image\n",
    "import nntools as nt\n",
    "import matplotlib.pyplot as plt\n",
    "from dataloader import VOCDataset, myimshow\n",
    "import model\n",
    "import glob\n",
    "class statsmanager(nt.StatsManager):\n",
    "    def __init__self():\n",
    "        super(statsmanager,self).__init__()\n",
    "\n",
    "    def init(self):\n",
    "        super(statsmanager,self).init()\n",
    "        self.m_ap=0\n",
    "\n",
    "    def accumulate(self,loss,x,y,d):\n",
    "        #Do m_ap calculations\n",
    "        super(statsmanager,self).accumulate(loss,x,y,d)\n",
    "    \n",
    "\n",
    "    def summarize(self):\n",
    "        loss=super(statsmanager,self).summarize()\n",
    "        return {'loss':loss}\n",
    "\n",
    "def plot(self,fig,ax1, ax2 ,im):\n",
    "    ax1.set_title('Image')\n",
    "    x,y=train_set[0]\n",
    "    myimshow(x,ax=ax1)\n",
    "    ax2.set_title('Yolo Net')\n",
    "    ax2.plot([exp1.history[k][0]['loss']for k in range(exp1.epoch)],label='Training Loss')\n",
    "    ax2.set_xlabel('Epochs')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.legend(loc='best')\n",
    "    plt.tight_layout()\n",
    "    fig.canvas.draw()\n",
    "\n",
    "lr=1e-3\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "vgg = model.Yolo(64)\n",
    "vgg.to(device)         \n",
    "adam=torch.optim.Adam(vgg.parameters(),lr=lr)\n",
    "stats_manager=statsmanager()\n",
    "train_set=VOCDataset('/datasets/ee285f-public/PascalVOC2012/')\n",
    "valid_set=VOCDataset('/datasets/ee285f-public/PascalVOC2012/', mode=\"val\")\n",
    "test_set=VOCDataset('/datasets/home/88/288/mkulkarn/VOCdevkit/VOC2007', mode=\"test\")\n",
    "x,y=train_set[0]\n",
    "\n",
    "exp1=nt.Experiment(vgg,train_set,valid_set,adam,stats_manager,batch_size=64,output_dir=\"run2\",perform_validation_during_training=True)\n",
    "fig, (ax1, ax2) = plt.subplots(ncols=2, nrows=1)\n",
    "exp1.load()\n",
    "exp1.run(num_epochs=150,plot=lambda exp:plot(exp,fig=fig,ax1=ax1, ax2=ax2 ,im=x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.utils.data as td\n",
    "import torchvision as tv\n",
    "import xml.etree.ElementTree as ET\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.misc import imread,imresize\n",
    "import cv2\n",
    "\n",
    "def decoder(pred):\n",
    "\n",
    "    \n",
    "    contain1 = pred[:,:,4].unsqueeze(2)\n",
    "    contain2 = pred[:,:,9].unsqueeze(2)\n",
    "    contain = torch.cat((contain1,contain2),2)\n",
    "    mask1 = contain > 0.1 \n",
    "    mask2 = (contain==contain.max())\n",
    "    mask = (mask1+mask2).gt(0)\n",
    "    boxes=[]\n",
    "    cls_indexs=[]\n",
    "    probs=[]\n",
    "    for i in range(7):\n",
    "        for j in range(7):\n",
    "            for b in range(2):\n",
    "              \n",
    "                xc=pred[i,j,b*5]\n",
    "                    \n",
    "                w=pred[i,j,b*5+2]\n",
    "                yc=pred[i,j,b*5+1]\n",
    "                h=pred[i,j,b*5+3]\n",
    "                xy = torch.FloatTensor([j,i])*(1./7)\n",
    "                x1=(xc-(w/2))\n",
    "                x2=(xc+(w/2))\n",
    "                y1=(yc-(h/2))\n",
    "                y2=(yc+(h/2))\n",
    "                box = pred[i,j,b*5:b*5+4]\n",
    "                bbox=torch.FloatTensor(box.size())\n",
    "                bbox[0]=x1\n",
    "                bbox[1]=y1\n",
    "                bbox[2]=x2\n",
    "                bbox[3]=y2\n",
    "                contain_prob=torch.FloatTensor([pred[i,j,b*5+4]])\n",
    "                max_prob,cls_index = torch.max(pred[i,j,10:],0)\n",
    "                if float((contain_prob*max_prob)[0]) > 0.1:\n",
    "                    boxes.append(bbox.view(1,4))\n",
    "                    cls_indexs.append(cls_index)\n",
    "                    probs.append(contain_prob*max_prob)\n",
    "    print(cls_indexs)\n",
    "    if len(boxes)==0 or len(cls_indexs)==0:\n",
    "        boxes = torch.zeros((1,4))\n",
    "        probs = torch.zeros(1)\n",
    "        cls_indexs = torch.zeros(1)\n",
    "    else:\n",
    "        boxes = torch.cat(boxes,0) #(n,4)\n",
    "        probs = torch.cat(probs,0) #(n,)\n",
    "        cls_indexs = torch.stack(cls_indexs,0) #(n,)\n",
    "    return boxes,probs,cls_indexs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nms(bboxes,scores,threshold=0.5):\n",
    "    '''\n",
    "    bboxes(tensor) [N,4]\n",
    "    scores(tensor) [N,]\n",
    "    '''\n",
    "    x1 = bboxes[:,0]\n",
    "    y1 = bboxes[:,1]\n",
    "    x2 = bboxes[:,2]\n",
    "    y2 = bboxes[:,3]\n",
    "    areas = (x2-x1) * (y2-y1)\n",
    "    _,order = scores.sort(0,descending=True)\n",
    "    keep = []\n",
    "    order1=order.numpy()\n",
    "    while order1.size > 0:\n",
    "\n",
    "        if order1.size == 1:\n",
    "            i = order1\n",
    "            keep.append(i)\n",
    "            break\n",
    "        i = order1[0]\n",
    "        keep.append(i)\n",
    "        xx1 = x1[order[1:]].clamp(min=x1[i].item())\n",
    "        yy1 = y1[order[1:]].clamp(min=y1[i].item())\n",
    "        xx2 = x2[order[1:]].clamp(max=x2[i].item())\n",
    "        yy2 = y2[order[1:]].clamp(max=y2[i].item())\n",
    "\n",
    "        w = (xx2-xx1).clamp(min=0)\n",
    "        h = (yy2-yy1).clamp(min=0)\n",
    "        inter = w*h\n",
    "\n",
    "        ovr = inter / (areas[i] + areas[order[1:]] - inter)\n",
    "        ids = (ovr<=threshold).nonzero().squeeze()\n",
    "        if ids.numel() == 0:\n",
    "            break\n",
    "        order = order[ids+1]\n",
    "        order1=order.numpy()\n",
    "    return torch.LongTensor(keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gt(img_path,lbl_path):\n",
    "    image_names=os.listdir(img_path)\n",
    "    image_names=[image.rstrip('.jpg') for image in image_names]\n",
    "    \n",
    "    \n",
    "    lbl_tree = ET.parse(lbl_path)\n",
    "    objs = []\n",
    "    bbox=[]\n",
    "    bboxes=[] \n",
    "    label=[]\n",
    "    labels=[]\n",
    "    \n",
    "    voc_dict = {\n",
    "                        'person':1, 'bird':2, 'cat':3, 'cow':4, 'dog':5, \n",
    "                        'horse':6, 'sheep':7, 'aeroplane':8, 'bicycle':9,\n",
    "                        'boat':10, 'bus':11, 'car':12, 'motorbike':13, 'train':14, \n",
    "                        'bottle':15, 'chair':16, 'diningtable':17, \n",
    "                        'pottedplant':18, 'sofa':19, 'tvmonitor':20\n",
    "                        }\n",
    "    \n",
    "    img = imread(img_path)\n",
    "    h,w,_=img.shape\n",
    "    for obj in lbl_tree.iter(tag='object'):\n",
    "        name = obj.find('name').text\n",
    "        for box in obj.iter(tag='bndbox'):\n",
    "            if name=='person':\n",
    "                xmax = box.find('xmax').text\n",
    "                xmin = box.find('xmin').text\n",
    "                ymax = box.find('ymax').text\n",
    "                ymin = box.find('ymin').text\n",
    "                break\n",
    "            xmax = box.find('xmax').text\n",
    "            xmin = box.find('xmin').text\n",
    "            ymax = box.find('ymax').text\n",
    "            ymin = box.find('ymin').text\n",
    "        attr = (voc_dict[name], float((float(xmin)+float(xmax))/2),float((float(ymin)+float(ymax))/2), float(float(xmax)-float(xmin)), float(float(ymax)-float(ymin)), 1)\n",
    "        attr1=float(xmin)/w,float(ymin)/h,float(xmax)/w,float(ymax)/h\n",
    "        objs.append(attr)\n",
    "        bbox.append(attr1)\n",
    "    box1=torch.Tensor(len(bbox),4)\n",
    "    for i in range(len(bbox)):\n",
    "        box1[i][0]=bbox[i][0]\n",
    "        box1[i][1]=bbox[i][1]\n",
    "        box1[i][2]=bbox[i][2]\n",
    "        box1[i][3]=bbox[i][3]\n",
    "    #bbox=torch.Tensor(bbox)\n",
    "    return box1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_gt=gt(img_path,lbl_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'a_gt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-b5a833626d64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_gt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrectangle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_gt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma_gt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_gt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma_gt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'a_gt' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(len(a_gt)):\n",
    "    cv2.rectangle(image,(a_gt[i][0]*w,a_gt[i][3]*h),(a_gt[i][2]*w,a_gt[i][1]*h),[255,0,255],2)\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y,z=test_set[i]\n",
    "x=x.view(1,3,224,224)\n",
    "x=x.to('cuda')\n",
    "op=vgg(x)\n",
    "op=op.view(7,7,30)\n",
    "a,b,c=decoder(op)\n",
    "keep=nms(a,b)\n",
    "a=a[keep]\n",
    "b=b[keep]\n",
    "c=c[keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a1,a2,a3,a4 in a:\n",
    "    cv2.rectangle(image,(a1*w,a4*h),(a3*w,a2*h),[255,255,0],2)\n",
    "plt.imshow(image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
